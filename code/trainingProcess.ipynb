{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "\n",
    "from classification.ElkanotoSVCClassifier import ElkanotoSVCClassifier\n",
    "from dataPreparation import DataPreparation\n",
    "from dataPreprocessing import DataPreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters for calculating the data for the csv (and their paths) and for the chosen features\n",
    "# doPreperation = False\n",
    "doPreprocessing = True\n",
    "featureFilePath = \"genomesWithFeatures.csv\"\n",
    "# genomeFilePath = \"genomes.csv\"\n",
    "# chosenFeatures = { \"kmer\": [5, 8], \"codon_translation\": [], \"dicodon_translation\" : [], \"sequence_length\" : []}\n",
    "chosenFeatures = { \"kmer\": [2, 3, 6, 8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doPreprocessing:\n",
    "    hosts = [f.name for f in os.scandir(\"../viral_genomes\") if f.is_dir()]\n",
    "    filesForHosts = {host: [f.name for f in os.scandir(\"../viral_genomes/\" + host) if f.is_file()] for host in hosts}\n",
    "\n",
    "    with open(featureFilePath, \"a\") as featureFile:\n",
    "        dataPreprocessor = DataPreprocessing.DataPreprocessing()\n",
    "        for host in hosts:\n",
    "            for filename in filesForHosts[host]:\n",
    "                with open(\"../viral_genomes/\" + host + \"/\" + filename, \"r\") as file:\n",
    "                    lines = file.readlines()\n",
    "                    sequence = \"\".join(lines[1:]).replace(\"\\n\", \"\")\n",
    "                    # flatten feature dict to list\n",
    "                    features = [x for v in dataPreprocessor.extractFeaturesFromGenome(sequence, chosenFeatures).values() for x in v]\n",
    "                    # write as csv\n",
    "                    featureFile.write(host + \",\" + filename.split(\".\")[0] + \",\" + \",\".join(map(str, features)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Preparation of Training Data\n",
    "# if doPreperation:\n",
    "#     dataPreperator = DataPreparation.DataPreparation()\n",
    "#     trainingGenomes = dataPreperator.loadTrainingGenomeSequences()\n",
    "#     with open(genomeFilePath, mode=\"w\", newline=\"\") as file:\n",
    "#       writer = csv.writer(file)\n",
    "#       writer.writerow([\"HostTaxID\", \"GenomeTaxID\", \"Sequence\"])\n",
    "#       for genome in trainingGenomes:\n",
    "#           writer.writerow(genome)\n",
    "\n",
    "# trainingGenomeData = pd.read_csv(genomeFilePath)\n",
    "# trainingGenomeData = list(trainingGenomeData.itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocessing of Training Data\n",
    "# if doPreprocessing:\n",
    "#     dataPreprocessor = DataPreprocessing.DataPreprocessing()\n",
    "#     featureDataframe = dataPreprocessor.calculateFeatureMatrix(trainingGenomeData,chosenFeatures)\n",
    "#     dataPreprocessor.saveFeatureMatrixAsCSV(featureDataframe, featureFilePath)\n",
    "\n",
    "# featureData = pd.read_csv(featureFilePath)\n",
    "\n",
    "# Convert the flat feature list into right format for classifier TODO: Do it better (best case before csv) for efficency\n",
    "# featureData['FeaturesFlat'] = featureData['FeaturesFlat'].apply(ast.literal_eval)\n",
    "# print(\"Phase2\")\n",
    "# featureData['FeaturesFlat'] = featureData['FeaturesFlat'].apply(lambda x: [float(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'featureData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     featuresPerHost[host] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Extract features of virus sequences for each host in seperate list and convert them to a np array\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfeatureData\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     16\u001b[0m     host \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHostTaxID\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     17\u001b[0m     features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeaturesFlat\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'featureData' is not defined"
     ]
    }
   ],
   "source": [
    "# Training of the PU-Classifier\n",
    "\n",
    "# Define hosts used to read files and hosts to build a classifier for\n",
    "hosts = [10090, 9534]\n",
    "hostsToClassify = [10090]\n",
    "\n",
    "classifiers = {}\n",
    "for host in hostsToClassify:\n",
    "    classifiers[host] = ElkanotoSVCClassifier()\n",
    "\n",
    "# Create dictionary of HostTaxIDs (as key) and empty lists (of feature lists for each datapoint) for each host (as value)\n",
    "featuresPerHost = {}\n",
    "for host in hosts:\n",
    "    featuresPerHost[host] = []\n",
    "\n",
    "# Extract features of virus sequences for each host in seperate list and convert them to a np array\n",
    "with open(featureFilePath) as file:\n",
    "    for line in file:\n",
    "        values = line.rstrip().split(\",\")\n",
    "        host = int(values[0])\n",
    "        if host in hosts:\n",
    "            featuresPerHost[host].append(list(map(float, values[2:])))\n",
    "\n",
    "# for _, row in featureData.iterrows():\n",
    "#     host = row['HostTaxID']\n",
    "#     features = np.array(row['FeaturesFlat'])\n",
    "#     featuresPerHost[host].append(features)\n",
    "\n",
    "for host in hosts:\n",
    "    featuresPerHost[host] = np.array(featuresPerHost[host])\n",
    "\n",
    "# Transform features (X) and host classes (y) into expected format of PU Classifier and run k-fold cross validation for each host\n",
    "X = np.concatenate([featuresPerHost[host] for host in hosts])\n",
    "\n",
    "def getYForHost(h):\n",
    "    y = []\n",
    "    for host in hosts:\n",
    "        y += [1 if host == h else 0] * len(featuresPerHost[host])\n",
    "    return np.array(y)\n",
    "\n",
    "scores = {}\n",
    "for host in hostsToClassify:\n",
    "    # load the training data\n",
    "    X = X\n",
    "    y = getYForHost(host)\n",
    "\n",
    "    # run k-fold cross validation\n",
    "    cv = KFold(n_splits=4, shuffle=True)\n",
    "    #cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    scores[host] = cross_validate(classifiers[host], X, y, cv=cv, scoring=['balanced_accuracy', 'recall', 'precision', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10090: {'fit_time': array([2.15569925, 2.35063291, 1.6938839 , 1.19818091]),\n",
       "  'score_time': array([0.19839478, 0.28084207, 0.21902609, 0.19310904]),\n",
       "  'test_balanced_accuracy': array([0.5, 0.5, 0.5, 0.5]),\n",
       "  'test_recall': array([1., 1., 1., 1.]),\n",
       "  'test_precision': array([0.82352941, 0.95588235, 0.85294118, 0.82089552]),\n",
       "  'test_f1': array([0.90322581, 0.97744361, 0.92063492, 0.90163934])},\n",
       " 9534: {'fit_time': array([1.057585  , 1.66847277, 1.07855105, 1.11113286]),\n",
       "  'score_time': array([0.21942401, 0.29591918, 0.20665598, 0.21692204]),\n",
       "  'test_balanced_accuracy': array([0.5, 0.5, 0.5, 0.5]),\n",
       "  'test_recall': array([1., 1., 1., 1.]),\n",
       "  'test_precision': array([0.13235294, 0.05882353, 0.20588235, 0.14925373]),\n",
       "  'test_f1': array([0.23376623, 0.11111111, 0.34146341, 0.25974026])}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation of the Training Process\n",
    "\n",
    "# print out the metrics we want to see using the scores\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virushunter2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
